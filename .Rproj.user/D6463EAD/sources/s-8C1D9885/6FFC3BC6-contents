---
title: "R_test"
author: "AZM"
date: "5/7/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<H1> Library Load in </H1>

First things first, let's grab 
  1. RedditExtractoR for scraping reddit posts 
  2. ttr for quant trading info & ticker lists
  3. 

```{r}
library(RedditExtractoR)
library(TTR)
library(curl)
library(tidyverse)
library(quanteda)
library(readr)

library(dplyr)

library(tm)

library(SnowballC)
```
```{r}

```


```{r}
master <- TTR::stockSymbols(exchange = c("AMEX", "NASDAQ", "NYSE", "ARCA", "BATS", "IEX"))[,c('Name', 'Symbol')]
```
```{r}
master
master[master$Symbol == "MGD"]
```


```{r}
posts <- find_thread_urls(subreddit="wallstreetbets", sort_by="new", period="hour")
```

```{r}
posts_test <- head(posts, n=5000L)
posts_test$index <- 1:nrow(posts_test)
posts_test

```
```{r}
corp <- corpus(posts_test, docid_field = "index", text_field = "text")
```

```{r}
x <- kwic(tokens(corp, remove_punct = TRUE, remove_numbers = TRUE), 
          pattern = master$Symbol,
          window = 8, case_insensitive = FALSE,
          )
x$index = x$docname
as.data.frame(x)
```
```{r}
library(sentimentr)
```
```{r}
add_In_Date <- posts_test[c("index","timestamp")]
rownames(add_In_Date) <- NULL
add_In_Date
```

```{r}
target <- as.data.frame(x)
target$sentence = paste(target$pre, target$post)
target
target_augment <- merge(target,add_In_Date,by="index")
target_sent <- get_sentences(target$sentence)
out <- with(target_augment, sentiment_by( get_sentences(target_augment), c("timestamp","pattern")))
plot(out)

#target_sent <- sentiment_by(target_sent)
#target$sentiment = target_sent$ave_sentiment
#target
```
